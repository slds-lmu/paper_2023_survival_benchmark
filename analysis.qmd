---
title: "Survival Benchmark: Analysis"
author: "Lukas"
date: now
date-format: "YYYY-MM-DD HH:mm:ss Z"
format: 
  html:
    code-fold: true
    toc: true
    embed-resources: false
    fig-align: center
    theme:
      light: flatly
      dark: darkly
editor: source
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(message = FALSE, warning = FALSE, echo = FALSE)
root = here::here()
source(file.path(root, "helpers.R"))

# Using active config as set per R_CONFIG_ACTIVE env var, see config.yml
# See https://rstudio.github.io/config/articles/config.html
cli::cli_alert_info("Loading config \"{Sys.getenv('R_CONFIG_ACTIVE', 'default')}\"")
settings = config::get(config = "beartooth")

###################################################################################################
### Packages
###################################################################################################
library(mlr3benchmark)
library(mlr3proba)
requireNamespace("mlr3extralearners")
# requires PMCMRplus, not included in renv because of issues installing it on cluster (libmpfr.so.6)
library(ggplot2)
library(kableExtra)

reg_dir = file.path(root, settings$reg_name)
result_path = here::here("results")


msr_tbl = measures_tbl()
#measures_eval = msr_tbl$measure
measures_eval_ids = msr_tbl$id
lrntab = load_lrntab()
tasktab = load_tasktab()

plot_results = function(
    bma, type = "box", measure_id = "harrell_c", tuning_measure_id = "harrell_c", ...
    ) {
  
  measure_label = msr_tbl[id == measure_id, label]
  tuning_measure_label = msr_tbl[id == tuning_measure_id, label]
  
  
  plot_type_label = switch(
    type,
    mean = "Mean Â± SE",
    box = "Boxplot",
    fn = "Post-hoc Friedman-Nemenyi",
    cd_n = "Critical Differences (Nemenyi)",
    cd_bd = "Critical Differences (Baseline KM)"
  )
  
  minimize = msr_tbl[id == measure_id, minimize]
  is_erv = msr_tbl[id == measure_id, erv]

  try({
    
    if (type %in% c("cd_n", "cd_bd") & !is_erv) {
      
      test = switch(type, cd_n = "nemenyi", cd_bd = "bd")
      
      p = mlr3viz::autoplot(bma, type = "cd", meas = measure_id, test = test, minimize = minimize, ...) +
        labs(
          caption = glue::glue("Tuning measure: {tuning_measure_label}
                               Evaluation measure: {measure_label}")
        )
    } else {
      p = mlr3viz::autoplot(bma, type = type, meas = measure_id, ...)
      
      p = p +
        labs(
          title = measure_label,
          subtitle = plot_type_label,
          x = NULL,
          y = measure_label,
          caption = glue::glue("Tuning measure: {tuning_measure_label}")
        )
    }
  
    if (type %in% c("box", "mean")) {
      p = p + scale_x_discrete(guide = guide_axis(n.dodge = 2))
      p = p + theme_minimal(base_size = 15)
    }
    
    if (type == "fn") {
      p = p + theme(
        axis.text.x = element_text(angle = 90),
        axis.text.y = element_text(angle = 0)
      )
    }
    
    print(p)
  }, silent = TRUE)
}

tablify = function(x, caption = NULL) {
  x |>
    kableExtra::kbl(caption = caption) |>
    kableExtra::kable_styling(bootstrap_options = c("striped", "hover"))
}

```

```{r setup-read}
# bmr_harrell_c  = readRDS(fs::path(result_path, settings$reg_name, "bmr_harrell_c.rds"))

bma_harrell_c  = readRDS(fs::path(result_path, settings$reg_name, "bma_harrell_c.rds"))
bmrtab_harrell_c = readRDS(fs::path(result_path, settings$reg_name, "bmrtab_harrell_c.rds"))
```

## Metadata

### Learners

Special cases for learners:

- `internal_cv` learners like `glmnet` and `CoxBoost` internally use a cross validation. CB is not tuned on the inner folds at all and uses its own method.
- `encode`/`scale` learners need factor encoding or scaling as part of the preprocessing pipeline
- `grid` learners have such small tuning spaces that a grid search is preferable

```{r}
lrntab |>
  dplyr::mutate(dplyr::across(dplyr::where(is.logical), \(x) ifelse(x, "\u2705", ""))) |>
  kableExtra::kbl() |>
  kableExtra::kable_styling()
```

### Tasks

```{r}
tasktab |>
  dplyr::select(task_id, n, p, n_uniq_t) |>
  dplyr::arrange(-n) |>
  kableExtra::kbl(col.names = c("Task", "N", "p", "# Unique Time Points")) |>
  kableExtra::kable_styling()
```

#### Checking PH Assumptions

Using global Schoenfeld test via `survival::coxph()` -> `survival::cox.zph()`.  
`NA`s indicate an error during `cox.zph()`.

```{r check-ph}
#| fig-width: 8
#| fig-height: 12
#| fig-align: center

tasks = load_task_data()

# survival::cox.zph(survival::coxph(survival::Surv(time, status) ~ ., data = tasks$CarpenterFdaData))
# survival::cox.zph(survival::coxph(survival::Surv(time, status) ~ ., data = tasks$hdfail))

tab_ph_test_dt = function(tasks, task_id) {
  cli::cli_alert_info("Checking {task_id}")
  fit_cph = survival::coxph(survival::Surv(time, status) ~ ., data = tasks[[task_id]])
  
  fit_zph = tryCatch(
    survival::cox.zph(fit_cph, terms = FALSE), 
    error = function(e) e
  )
  
  if (inherits(fit_zph, "error")) {
    cli::cli_alert_danger("Error in cox.zph for {task_id}")
    return(data.table(
      task = task_id, chisq = NA_real_, df = NA_real_, p = NA_real_
    ))
  }
  
  dt = as.data.table(fit_zph$table, keep.rownames = "feature")
  dt = dt[feature == "GLOBAL", ]
  dt[, task := ..task_id]
  dt[, feature := NULL]
  dt[, p := format.pval(p, eps = 0.05)]
  data.table::setcolorder(dt, c("task", "chisq", "df", "p"))
  dt
}

global_dt = data.table::rbindlist(lapply(names(tasks), \(x) tab_ph_test_dt(tasks, x)))

global_dt |>
  kbl(caption = "Global Schoenfeld Test") |>
  kable_styling() |>
  row_spec(row = which(global_dt$p == "< 0.05"), bold = TRUE)

# tab_ph_test = function(tasks, task_id) {
#   cli::cli_alert_info("Checking {task_id}")
#   fit_cph = survival::coxph(survival::Surv(time, status) ~ ., data = tasks[[task_id]])
#   
#   fit_zph = tryCatch(
#     survival::cox.zph(fit_cph, terms = FALSE), 
#     error = function(e) e
#   )
#   
#   if (inherits(fit_zph, "error")) {
#     cli::cli_alert_danger("Error in cox.zph for {task_id}")
#     return(NULL)
#   }
#   
#   testdt = as.data.table(fit_zph$table, keep.rownames = "feature")
#   
#   no_violation = testdt[feature == "GLOBAL", p] >= 0.05
#   if (no_violation) {
#     return("\nSchoenfeld test globally insignificant (p >= 0.05)\n\n")
#   }
#   
#   print(survminer::ggcoxzph(fit_zph))
# 
#   testdt |>
#     kbl(caption = task_id) |>
#     kable_styling() |>
#     row_spec(row = which(testdt$p < 0.05), bold = TRUE)
# }
# 
# for (tid in names(tasks)) {
#   mlr3misc::catf("##### %s \n\n", tid)
#   cat(tab_ph_test(tasks, tid))
# }

```

</details>

## Completed jobs

```{r}
bma_harrell_c$data[, .(n = .N), by = .(learner_id)] |>
  tablify(caption = "Completed jobs by learner")

bma_harrell_c$data[, .(n = .N), by = .(task_id)] |>
  tablify(caption = "Completed jobs by task")
```


## Counting Errors

### Based on outer resampling folds

```{r sanity-check}
# bmrtab_harrell_c |> 
#   knitr::kable() |> 
#   kableExtra::kable_styling()
 
bmrtab_harrell_c[errors > 0,] |> 
  tablify()

bmrtab_harrell_c[errors > 0,][, .(n = .N), by = .(task_id)] |> 
  tablify()

bmrtab_harrell_c[errors > 0,][, .(n = .N), by = .(learner_id)] |> 
  tablify()

```

### Imputing invalid values in `bma`

By substituting them with fixed bad scores

- Graf Score (Improper) -> ?
- Graf Score (Improper, ERV) -> ?
- Alpha -> 10 (same as D-Calibration)

```{r}
xdat = bma_harrell_c$data

# Excluding SSVM results as there are no usable ones
xdat = xdat[learner_id != "SSVM", ]
xdat = xdat[, learner_id := factor(learner_id, levels = setdiff(levels(xdat$learner_id), "SSVM"))]

invalid_tbl = lapply(names(xdat), \(x) {
  tibble::tibble(
    measure = x,
    NA_n = sum(is.na(xdat[[x]]) & !is.nan(xdat[[x]])),
    Inf_n = sum(is.infinite(xdat[[x]])),
    NaN_n = sum(is.nan(xdat[[x]])),
    total = NA_n + Inf_n + NaN_n
  )
}) |>
  data.table::rbindlist(use.names = TRUE) |>
  dplyr::filter(total > 0)

invalid_tbl |>
  tablify()

is_valid = function(x) {
  is.finite(x) & !is.na(x) & !is.nan(x)
}

xdat$caliba[!is_valid(xdat$caliba)] <- 10
xdat$graf_improper[!is_valid(xdat$graf_improper)] <- 1
xdat$graf_improper_erv[!is_valid(xdat$graf_improper_erv)] <- 1
# max(xdat$graf_improper[is_valid(xdat$graf_improper)])

bma_harrell_c = as_benchmark_aggr(xdat)
saveRDS(bma_harrell_c, here::here("results/registry_beartooth/bma_clean_harrell_c.rds"))
```


### Errors from tuning archives

Proportion of errors relative to total number of evaluations, i.e. `nrow()` of the associated tuning archives.

```{r get-archives}
#| cache: true

archives = reassemble_archives(reg_dir = reg_dir, result_path = result_path, keep_logs = FALSE)
archives[, archive_length := vapply(archive, nrow, 1)]
#archive_errors = archives[errors_sum > 0, c("tune_measure", "task_id", "learner_id", "errors_sum")]

archives[, .(errors_total = sum(errors_sum), evals_total = sum(archive_length)), by = .(tune_measure, learner_id)] |>
  dplyr::filter(errors_total > 0) |>
  dplyr::select(learner_id, tune_measure, errors_total, evals_total) |>
  dplyr::arrange(learner_id) |>
  dplyr::mutate(error_prop = round(100 * errors_total / evals_total, 1)) |>
  tablify()
```


# Eval Measures

## Tuned on: Harrell's C

### Raw scores (`bma`)

```{r}
bma_harrell_c$data |>
  dplyr::mutate(dplyr::across(dplyr::where(is.numeric), \(x) round(x, 3))) |>
  reactable::reactable(
    sortable = TRUE, filterable = TRUE, searchable = TRUE
  )
```


### Global Friedman Test

::: {.callout-warning}
## Benchmark is not complete yet

Statistical tests should not be considered valid until all results are in.
:::

```{r friedman-harrell-c}
aggr_friedman_harrell = aggr_friedman_global(bma_harrell_c, measures_eval_ids = msr_tbl$id, conf.level = 0.95)

aggr_friedman_harrell |>
  tablify()
```

### Mean + SE

```{r meanse}
#| fig-width: 10
for (measure_id in measures_eval_ids) {
  plot_results(bma = bma_harrell_c, type = "mean", measure_id = measure_id, tuning_measure_id = "harrell_c")
}
```

### Boxplots

```{r boxplot}
#| fig-width: 10
for (measure_id in measures_eval_ids) {
  plot_results(bma = bma_harrell_c, type = "box", measure_id = measure_id, tuning_measure_id = "harrell_c")
}

```

### Friedman-Nemenyi

```{r friedman-nemenyi}
#| fig-width: 10
for (measure_id in measures_eval_ids) {
  plot_results(bma = bma_harrell_c, type = "fn", measure_id = measure_id, tuning_measure_id = "harrell_c")
}
```

### Critical Difference Plots: Nemenyi

```{r critical-difference}
#| fig-width: 10
for (measure_id in measures_eval_ids) {
  plot_results(bma = bma_harrell_c, type = "cd_n", measure_id = measure_id, tuning_measure_id = "harrell_c", ratio = 1.05)
}
```
