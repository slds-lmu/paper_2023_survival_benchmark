---
title: "Benchmark Status"
author: Lukas
date: now
date-format: "YYYY-MM-DD HH:mm:ss Z"
format: 
  html:
   toc: true
   embed-resources: false
   code-fold: true
   fig-align: center
   theme:
     light: flatly
     dark: darkly
editor: source
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)

library(data.table)
library(batchtools)
library(kableExtra)
library(dplyr)
library(ggplot2)

# Assumes batchmark.R is run beforehand
reg = loadRegistry(conf$reg_dir, writeable = FALSE)
tasktab = load_tasktab()
#lrntab = load_lrntab()
tab = collect_job_table(
  keep_columns = c("job.id", "repl", "tags", "task_id", "learner_id"),
  optional_columns = c("time.running", "submitted", "started", "done", "comment", "partition", "qos")
)

tab[,
  time_cat := data.table::fcase(
    est_total_hours <= 1,
    "shortest",
    est_total_hours <= 10,
    "fast",
    est_total_hours <= 2.5 * 24,
    "normal",
    est_total_hours < 160,
    "long",
    est_total_hours >= 160,
    "maximum"
  )
]
tab[, time_cat := factor(time_cat, c("shortest", "fast", "normal", "long", "maximum"))]

# Subset to jobs relevant for runtime estimate
if (config::is_active("runtime")) tab = tab[repl == 1 & measure != "isbs", ]

tab[, time.running := as.numeric(time.running, unit = "secs")]
tab[, time.running.hms := hms::hms(seconds = round(time.running, 1))]
tab[, time.running.days := round(time.running / 3600 / 24, 2)]

tab[, done := as.POSIXct(done, tz = "Europe/Berlin")]
tab[, submitted := as.POSIXct(submitted, tz = "Europe/Berlin")]
tab[, started := as.POSIXct(started, tz = "Europe/Berlin")]

tab_running = ijoin(tab, findRunning())

job_completion = tab |>
  dplyr::filter(!is.na(done)) |>
  dplyr::arrange(done) |>
  dplyr::mutate(
    k = dplyr::row_number(),
    prop = k / nrow(tab)
  )

complete_n = nrow(job_completion)
complete_perc = round(100 * complete_n / nrow(tab), 1)

job_milestones = tibble::tribble(
  ~type, ~first, ~last,
  "submitted", min(tab$submitted, na.rm = TRUE), max(tab$submitted, na.rm = TRUE),
  "started",   min(tab$started, na.rm = TRUE), max(tab$started, na.rm = TRUE),
  "done",      min(tab$done, na.rm = TRUE), max(tab$done, na.rm = TRUE)
) |>
  dplyr::mutate(
    days_between = round(difftime(last, first, units = "days"), 1)
  )

took_days = round(as.numeric(difftime(max(tab$done, na.rm = TRUE), min(tab$submitted, na.rm = TRUE), units = "days")), 1)
took_days_sequential = sum(tab$time.running.days, na.rm = TRUE)
```

Status as of `r format(Sys.time(), tz = "Europe/Berlin", format = "%F %T (%Z)")`

Overall completion: **`r complete_n`** / `r nrow(tab)` (**`r complete_perc`%**).  

It took **`r took_days`** days all in all, with a sequential runtime of **`r took_days_sequential`** days (so far).

Batchtools' status report:

```{r bt-getStatus}
batchtools::getStatus()
```

Note that running jobs are misreported as expired here.

```{r milestones-tab}
job_milestones |> 
  tablify()
```

```{r runtime-per-task-tab}
#| eval: false

job_completion |>
  group_by(task_id) |>
  summarise(
    q25 = quantile(time.running.days, 0.25),
    median = median(time.running.days),
    mean = mean(time.running.days),
    q75 = quantile(time.running.days, 0.75),
    total_sequential = sum(time.running.days)
  ) |>
  arrange(-mean) |>
  mutate(across(where(is.numeric), \(x) round(x, 1))) |>
  tablify(caption = "Job runtime per task in days")
```

```{r runtime-per-learner-tab}
#| eval: false

job_completion |>
  group_by(learner_id) |>
  summarise(
    q25 = quantile(time.running.days, 0.25),
    median = median(time.running.days),
    mean = mean(time.running.days),
    q75 = quantile(time.running.days, 0.75),
    total_sequential = sum(time.running.days),
    total_guesstimated = total_sequential / 5 / 32
  ) |>
  arrange(-mean) |>
  mutate(across(where(is.numeric), \(x) round(x, 1))) |>
  tablify(caption = "Job runtime per learner in days")
```


```{r job-completion-total}
#| fig-width: 10

job_completion |>
  dplyr::mutate(done = as.POSIXct(done, tz = "Europe/Berlin")) |>
  ggplot(aes(x = done, y = prop)) +
  geom_step(linewidth = 1.5) +
  scale_y_continuous(
    breaks = seq(0, 1, .2),
    labels = scales::label_percent(), 
    limits = c(0, 1),
    sec.axis = sec_axis(transform = \(x) x * nrow(tab))
  ) +
#  scale_x_datetime(
#    date_breaks = "7 days", 
#    date_labels = "%b %d",
#    date_minor_breaks = "1 day"
#  ) +
  labs(
    title = "Survival Benchmark Completion Progress",
    subtitle = "Cumulative percentage of finished jobs over time",
    x = "Date", y = glue::glue("% of total jobs [{nrow(tab)}]")
  ) +
  theme_minimal(base_size = 14)
```

```{r job-completion-runtime-group}
#| fig-width: 10
#| 
tab |>
  dplyr::select(job.id, time_cat, done) |>
  dplyr::group_by(time_cat) |>
  dplyr::arrange(done) |>
  dplyr::mutate(
    k = cumsum(!is.na(done)),
    prop = k / dplyr::n()
  ) |> 
  ggplot(aes(x = done, y = prop, color = time_cat)) +
  geom_step(linewidth = 1.5) +
  scale_y_continuous(
    breaks = seq(0, 1, .2),
    labels = scales::label_percent(), 
    limits = c(0, 1)
  ) +
  scale_color_viridis_d() + 
  labs(
    title = "Survival Benchmark Completion Progress",
    subtitle = "Cumulative percentage of finished jobs over time",
    x = "Date", y = glue::glue("% of jobs within group"),
    color = "Runtime Group"
  ) +
  theme_minimal(base_size = 14)
```

Ommitting KM, NEL, CPH because they're basically instant

```{r job-completion-learner-id}
#| fig-width: 12
#| fig-height: 10

tab |>
  dplyr::select(job.id, learner_id, done) |>
  dplyr::filter(!(learner_id %in% c("KM", "NEL", "CPH"))) |>
  dplyr::group_by(learner_id) |>
  dplyr::arrange(done) |>
  dplyr::mutate(
    learner_id = factor(learner_id, levels = unique(tab$learner_id)),
    k = cumsum(!is.na(done)),
    prop = k / dplyr::n()
  ) |> 
  ggplot(aes(x = done, y = prop)) +
  geom_step(linewidth = 1.5) +
  facet_wrap(vars(learner_id), ncol = 4) +
  scale_y_continuous(
    breaks = seq(0, 1, .25),
    labels = scales::label_percent(), 
    limits = c(0, 1)
  ) +
  labs(
    title = "Survival Benchmark Progress",
    subtitle = "Cumulative percentage of finished jobs over time",
    x = "Date", y = glue::glue("% of jobs within group")
  ) +
  theme_minimal(base_size = 14) +
  theme(
    axis.text.x = element_text(angle = -90),
    panel.grid.minor = element_blank(),
    panel.grid.major.x = element_blank()
  )
```

### Recently completed jobs

```{r}
job_completion |>
  slice_tail(n = 10) |>
  select(learner_id, task_id, job.id, repl, measure, time.running.hms, time.running.days) |>
  tablify()
```

### Currently running jobs

```{r currently-running, eval=nrow(tab_running) > 0}
tab_running |>
  arrange(desc(time.running)) |>
  select(learner_id, task_id, job.id, repl, measure, time.running.hms, time.running.days) |>
  reactable::reactable(
    sortable = TRUE, filterable = TRUE, defaultPageSize = 20
  )
```

## Runtime Group

```{r status-by-group}
check_job_state(tab, by = "time_cat") |>
  dplyr::rename(runtime_group = time_cat) |>
  tablify()
```

## Tuning Measure

```{r status-by-measure}
check_job_state(tab, by = "measure") |>
  tablify()
```

## Learner

```{r status-by-learner}
check_job_state(tab, by = "learner_id") |>
  tablify()
```

## Task

```{r status-by-task}
check_job_state(tab, by = "task_id") |>
  ijoin(tasktab[, .(task_id, n, p, events)], by = "task_id") |>
  dplyr::mutate(
    task_id = glue::glue("{task_id} ({n} x {p})")
  ) |>
  dplyr::select(task_id, events, dplyr::everything(), -n, -p) |>
  dplyr::arrange(-events) |>
  tablify()
```
